# üéØ Pixeltable Multimodal Demo

A comprehensive demonstration of **Pixeltable** - the unified framework for multimodal AI applications.

![Pixeltable Architecture](https://raw.githubusercontent.com/pixeltable/pixeltable/main/docs/source/data/pixeltable-overview.png)

## üöÄ What is Pixeltable?

**Pixeltable** revolutionizes multimodal AI development by unifying everything into a single table-based interface:

- üìÑ **Documents** with automatic chunking and embedding
- üñºÔ∏è **Images** with vision AI analysis
- üé• **Videos** with frame extraction
- üéµ **Audio** with transcription
- ü§ñ **LLM Integration** (OpenAI, HuggingFace)
- üîç **Vector Search** built-in
- üìä **RAG Systems** in ~30 lines of code

### ‚ùå Traditional Approach
- Multiple services (Pinecone, PostgreSQL, S3)
- Complex pipeline orchestration (Airflow)
- 500+ lines of glue code
- Difficult to maintain and debug

### ‚úÖ Pixeltable Approach
- Single unified system
- Automatic computation
- ~30 lines of code
- Built-in version control

## üì¶ Installation

### Prerequisites
- Python 3.9+
- OpenAI API key (in `.env` file)

### Quick Setup

```bash
# 1. Make setup script executable
chmod +x setup.sh

# 2. Run setup (creates .venv and installs dependencies)
./setup.sh

# 3. Activate virtual environment
source .venv/bin/activate
```

### Manual Setup

```bash
# Create virtual environment
python3 -m venv .venv
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

## üéÆ Running the Demo

### 1. Web Application (Streamlit)

Beautiful interactive web interface with:
- üìÑ Document RAG Q&A
- üñºÔ∏è Image analysis with GPT-4 Vision
- üí° Educational content about Pixeltable

```bash
streamlit run app.py
```

**Features:**
- Upload documents (PDF, TXT) and ask questions
- Upload images for AI-powered analysis
- Visual comparison of traditional vs Pixeltable approach
- Live examples of multimodal processing

### 2. Jupyter Notebook

Step-by-step tutorial with executable examples:

```bash
jupyter notebook pixeltable_demo.ipynb
```

**Contents:**
1. ‚úÖ Setup and installation
2. üí∞ Automatic profit calculation example
3. üñºÔ∏è Image analysis with GPT-4 Vision
4. üîç Image similarity search with CLIP
5. üìÑ Complete RAG system (30 lines!)
6. üîÑ Incremental updates demonstration
7. üé® Custom user-defined functions

## üìÅ Project Structure

```
pixeltable-demo/
‚îú‚îÄ‚îÄ app.py                    # Streamlit web application
‚îú‚îÄ‚îÄ pixeltable_demo.ipynb     # Jupyter notebook tutorial
‚îú‚îÄ‚îÄ requirements.txt          # Python dependencies
‚îú‚îÄ‚îÄ setup.sh                  # Setup script
‚îú‚îÄ‚îÄ .env                      # API keys (not in git)
‚îú‚îÄ‚îÄ README.md                 # This file
‚îî‚îÄ‚îÄ project.md                # Project documentation
```

## üéØ Key Features Demonstrated

### 1. Automatic Computation
```python
# Add computed column - automatically calculates for ALL rows
films.add_computed_column(profit=(films.revenue - films.budget))
```

### 2. Image Analysis
```python
# Add GPT-4 Vision - automatically analyzes all images
images.add_computed_column(
    vision_description=openai.vision(
        model='gpt-4o-mini',
        prompt="Describe this image",
        image=images.input_image
    )
)
```

### 3. Complete RAG System
```python
# Create documents table
docs = pxt.create_table('docs', {'doc': pxt.Document})

# Auto-chunk documents
chunks = pxt.create_view('chunks', docs, 
    iterator=DocumentSplitter.create(document=docs.doc, separators='sentence'))

# Add embedding index using .using()
embed_model = huggingface.sentence_transformer.using(model_id='all-MiniLM-L6-v2')
chunks.add_embedding_index('text', string_embed=embed_model)

# Create Q&A with automatic answer generation
qa = pxt.create_table('qa', {'prompt': pxt.String})
qa.add_computed_column(answer=openai.chat_completions(...))
```

**That's it! ~30 lines for a complete RAG system!**

## üí° Use Cases

1. **üìÑ Document Q&A (RAG)**
   - Legal document analysis
   - Research paper exploration
   - Knowledge base search

2. **üñºÔ∏è Image Search**
   - Product catalog search
   - Medical image retrieval
   - Content moderation

3. **üé• Video Analysis**
   - Content summarization
   - Scene detection
   - Automated tagging

4. **ü§ñ AI Agents**
   - Tool call history
   - Conversation tracking
   - State management

5. **üìä Dataset Preparation**
   - ML dataset creation
   - Data versioning
   - Feature engineering

## üîë Environment Setup

Create a `.env` file with your API keys:

```bash
OPENAI_API_KEY=your_openai_api_key_here
```

## üéì Learning Path

### For Beginners
1. Start with the **Streamlit app** (`streamlit run app.py`)
2. Explore the "Why Pixeltable?" section
3. Try uploading a document and asking questions

### For Developers
1. Open the **Jupyter notebook** (`jupyter notebook pixeltable_demo.ipynb`)
2. Execute each cell to see how Pixeltable works
3. Modify examples with your own data
4. Build your own multimodal application!

## üèóÔ∏è Architecture

### Traditional ML Stack
```
Application
    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Pinecone/Weaviate (Vector DB)      ‚îÇ
‚îÇ PostgreSQL (Metadata)               ‚îÇ
‚îÇ S3/MinIO (Object Storage)           ‚îÇ
‚îÇ Airflow (Pipeline Orchestration)    ‚îÇ
‚îÇ Python Scripts (Glue Code)          ‚îÇ
‚îÇ API Wrappers (OpenAI, HuggingFace)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Pixeltable Stack
```
Application
    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Pixeltable (Everything!)            ‚îÇ
‚îÇ  - Tables with computed columns     ‚îÇ
‚îÇ  - Automatic updates                ‚îÇ
‚îÇ  - Built-in versioning              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üìä Performance Benefits

| Metric | Traditional | Pixeltable |
|--------|-------------|------------|
| Setup Time | Hours | Minutes |
| Lines of Code (RAG) | 500+ | ~30 |
| External Services | 5+ | 1 |
| Maintenance Complexity | High | Low |
| Version Control | Manual | Built-in |
| Incremental Updates | Custom Code | Automatic |

## üöß Common Issues & Solutions

### Issue: OpenAI API Key Error
```bash
# Solution: Ensure .env file exists with correct key
echo "OPENAI_API_KEY=your_key_here" > .env
```

### Issue: Module Not Found
```bash
# Solution: Activate virtual environment
source .venv/bin/activate
pip install -r requirements.txt
```

### Issue: Port Already in Use (Streamlit)
```bash
# Solution: Use different port
streamlit run app.py --server.port 8502
```

## üìö Resources

- **Official Docs**: https://pixeltable.readme.io/
- **GitHub**: https://github.com/pixeltable/pixeltable
- **Examples**: https://github.com/pixeltable/pixeltable/tree/main/docs/tutorials
- **Discord**: https://discord.gg/pixeltable

## üéØ Next Steps

1. **Experiment**: Modify the notebook examples with your data
2. **Build**: Create your own multimodal application
3. **Share**: Share your Pixeltable projects!

## ü§ù Contributing

This is a demo project. For contributions to Pixeltable itself:
- Visit https://github.com/pixeltable/pixeltable
- Check their contribution guidelines

## üìù License

This demo project is MIT licensed. Pixeltable itself has its own license.

## üôè Acknowledgments

- **Pixeltable Team** for creating this amazing framework
- **OpenAI** for GPT-4 and Vision APIs
- **HuggingFace** for open-source models

---

## üíª Quick Commands Reference

```bash
# Setup
./setup.sh
source .venv/bin/activate

# Run Streamlit app
streamlit run app.py

# Run Jupyter notebook
jupyter notebook pixeltable_demo.ipynb

# Install new package
pip install package-name
pip freeze > requirements.txt

# Deactivate virtual environment
deactivate
```

---

**Built with ‚ù§Ô∏è using Pixeltable**

For questions or issues, please refer to the [Pixeltable documentation](https://pixeltable.readme.io/).
