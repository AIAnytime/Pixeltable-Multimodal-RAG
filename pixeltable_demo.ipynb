{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pixeltable Complete Demo\n",
        "## Unified Multimodal AI Framework\n",
        "\n",
        "This notebook demonstrates **Pixeltable** - a revolutionary framework that unifies multimodal AI development."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup\n",
        "import pixeltable as pxt\n",
        "from pixeltable.functions import openai, huggingface\n",
        "from pixeltable.iterators import DocumentSplitter\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "print(\"Setup complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 1: Auto-Calculated Profits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pxt.create_dir(\"tutorial\", ignore_errors=True)\n",
        "films = pxt.create_table(\"tutorial.films\", {\"name\": pxt.String, \"revenue\": pxt.Float, \"budget\": pxt.Float}, if_exists=\"replace\")\n",
        "films.insert([{\"name\": \"Inside Out\", \"revenue\": 800.5, \"budget\": 200.0}, {\"name\": \"Toy Story\", \"revenue\": 1073.4, \"budget\": 200.0}])\n",
        "films.add_computed_column(profit=(films.revenue - films.budget), if_exists=\"replace\")\n",
        "print(films.select(films.name, films.profit).collect())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 2: Image Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "images = pxt.create_table(\"tutorial.images\", {\"input_image\": pxt.Image}, if_exists=\"replace\")\n",
        "images.add_computed_column(vision_description=openai.vision(model=\"gpt-4o-mini\", prompt=\"Describe this image\", image=images.input_image))\n",
        "print(\"Image analysis ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 3: Complete RAG System"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create documents table\n",
        "docs = pxt.create_table(\"tutorial.docs\", {\"doc\": pxt.Document}, if_exists=\"replace\")\n",
        "print(\"Documents table created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create chunks view\n",
        "chunks = pxt.create_view(\"tutorial.doc_chunks\", docs, iterator=DocumentSplitter.create(document=docs.doc, separators=\"sentence\"), if_exists=\"replace\")\n",
        "print(\"Chunks view created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add embeddings\n",
        "embed = huggingface.sentence_transformer(chunks.text, model_id=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "chunks.add_computed_column(embedding=embed)\n",
        "print(\"Embeddings added\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Insert sample document\n",
        "import tempfile\n",
        "sample = \"Pixeltable simplifies AI development. It provides unified table interface for multimodal data.\"\n",
        "with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".txt\", delete=False) as f:\n",
        "    f.write(sample)\n",
        "    doc_path = f.name\n",
        "docs.insert([{\"doc\": doc_path}])\n",
        "print(f\"Document inserted, chunks: {len(chunks.select().collect())}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create Q&A system\n",
        "@pxt.query\n",
        "def get_context(query_text: str, limit: int = 3):\n",
        "    sim = chunks.embedding.similarity(query_text)\n",
        "    return chunks.order_by(sim, asc=False).limit(limit).select(chunks.text)\n",
        "\n",
        "qa = pxt.create_table(\"tutorial.qa\", {\"prompt\": pxt.String}, if_exists=\"replace\")\n",
        "qa.add_computed_column(context=get_context(qa.prompt))\n",
        "qa.add_computed_column(final_prompt=pxt.functions.string.format(\"CONTEXT:{0}\\nQUESTION:{1}\", qa.context, qa.prompt))\n",
        "qa.add_computed_column(answer=openai.chat_completions(model=\"gpt-4o-mini\", messages=[{\"role\":\"user\",\"content\":qa.final_prompt}]).choices[0].message.content)\n",
        "print(\"RAG system ready!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ask questions\n",
        "qa.insert([{\"prompt\": \"What is Pixeltable?\"}])\n",
        "result = qa.select(qa.answer).tail(1).collect()\n",
        "print(f\"Answer: {result[0][\"answer\"]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Takeaways\n",
        "\n",
        "- **Unified**: Everything in tables\n",
        "- **Automatic**: Computed columns update automatically\n",
        "- **Incremental**: Only changed data recomputed\n",
        "- **Simple**: 30 lines vs 500+ for RAG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
